{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - GridSearchCV\n",
    "\n",
    "Grid Search CV Logistic Regression\n",
    "Logistic regression is a very fast classifier.\n",
    "I am using grid search to find best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   18.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9573333333333334\n",
      "\n",
      "Best Params: {'penalty': 'l2', 'C': 1.0, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=1)\n",
    "lr_params = {'penalty': ['l1','l2'],\n",
    "          'solver':['liblinear'],\n",
    "          'C': np.logspace(-10,10,21)}\n",
    "\n",
    "lr_grid = GridSearchCV(lr, param_grid=lr_params, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# fit with the tranformed tfidf matrix as X\n",
    "lr_grid.fit(X_train_mat, y_train)\n",
    "\n",
    "print 'Best Score:', lr_grid.best_score_\n",
    "print\n",
    "# assign the best estimator to a variable:\n",
    "best_lr = lr_grid.best_estimator_\n",
    "print 'Best Params:', lr_grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "l2 is ridgeeeeeeee\n",
    "- notes might help - Lasso was chosen: this indicates that maybe unimportant (noise) variables\n",
    "- is more of an issue in our data than multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>lem_words</th>\n",
       "      <th>lem_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>They refuse to seat parties of 3 or more on we...</td>\n",
       "      <td>refuse seat party more weekend</td>\n",
       "      <td>VB NN NN JJ NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>This is a nice pizza place with good selection...</td>\n",
       "      <td>be nice pizza place good selection thin crust ...</td>\n",
       "      <td>VB JJ NN NN JJ NN JJ NN NN VB NN NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Indoor was very cozy and cute.</td>\n",
       "      <td>indoor be very cozy cute</td>\n",
       "      <td>JJ VB RB JJ JJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                           sentence  \\\n",
       "0       0.0  They refuse to seat parties of 3 or more on we...   \n",
       "1       2.0  This is a nice pizza place with good selection...   \n",
       "2       2.0                     Indoor was very cozy and cute.   \n",
       "\n",
       "                                           lem_words  \\\n",
       "0                     refuse seat party more weekend   \n",
       "1  be nice pizza place good selection thin crust ...   \n",
       "2                           indoor be very cozy cute   \n",
       "\n",
       "                              lem_type  \n",
       "0                       VB NN NN JJ NN  \n",
       "1  VB JJ NN NN JJ NN JJ NN NN VB NN NN  \n",
       "2                       JJ VB RB JJ JJ  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = testing.lem_words\n",
    "y_test = testing['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params on testing: 0.8145161290322581\n",
      "Number of classification errors: 164.0\n",
      "Total: 496\n"
     ]
    }
   ],
   "source": [
    "# transform with cvec and predict on best log reg\n",
    "X_test_mat = cvec.transform(X_test)\n",
    "y_pred = best_lr.predict(X_test_mat)\n",
    "\n",
    "print 'Best Model on testing:', accuracy_score(y_test, y_pred)\n",
    "print \"Number of classification errors:\", np.abs(y_pred - y_test).sum() \n",
    "print 'Total:', len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params on testing data\n",
    "- TFDIF was fitted on the training data which will be used to transfomation the words in testing into a sparse matrix\n",
    "- This will then use the logistic regressions best parameters which were fit for thr training data to predict sentiment/ y_hat for my testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the testing data\n",
    "X_test_testing = tvec.transform(testing.words)\n",
    "\n",
    "# predictions and predictive probabilities\n",
    "y_hat = best_lr_tvec.predict(X_test_testing)\n",
    "y_hat_pp = best_lr_tvec.predict_proba(X_test_testing)\n",
    "y_hat_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression gave a good score in classifying the predictors but will try different classifiers to determine best accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_lr_tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Params on testing data\n",
    "- TFDIF was fitted on the training data which will be used to transfomation the words in testing into a sparse matrix\n",
    "- This will then use the logistic regressions best parameters which were fit for thr training data to predict sentiment/ y_hat for my testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tvec_df  = pd.DataFrame(tvec.transform(training.words).todense(),\n",
    "#                    columns=tvec.get_feature_names())\n",
    "# tvec_df.sum(axis=0).sort_values(ascending=False)[:10]\n",
    "# top words...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
