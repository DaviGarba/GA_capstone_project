{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params on testing data\n",
    "- TFDIF was fitted on the training data which will be used to transfomation the words in testing into a sparse matrix\n",
    "- This will then use the logistic regressions best parameters which were fit for thr training data to predict sentiment/ y_hat for my testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the testing data\n",
    "X_test_testing = tvec.transform(testing.words)\n",
    "\n",
    "# predictions and predictive probabilities\n",
    "y_hat = best_lr_tvec.predict(X_test_testing)\n",
    "y_hat_pp = best_lr_tvec.predict_proba(X_test_testing)\n",
    "y_hat_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression gave a good score in classifying the predictors but will try different classifiers to determine best accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_lr_tvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## next\n",
    "- Should i try a different approach by grid searching the vectorisers to see which ones perform best rather than the classifier?? \n",
    "- next steps are to loop through a list of classifiers choose the best one/s performing then grid search in a pipline with the vectoriser to optimise both params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Grid Search CV Logistic Regression\n",
    "-  Logistic regression is a very fast classifier. \n",
    "- I am using grid search to find best hyperparameters.\n",
    "- random_state=1 lr param fixed random... for l1 l2 ???????\n",
    "\n",
    "- For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used??? arguement?\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "\n",
    "lr = LogisticRegression(random_state=1)\n",
    "\n",
    "params = {'penalty': ['l1','l2'],\n",
    "          'solver':['liblinear'],\n",
    "          'C': np.logspace(-10,10,21)}\n",
    "\n",
    "grid = GridSearchCV(lr,param_grid=params,cv=5, n_jobs = -1, verbose= 1)\n",
    "\n",
    "#### Classify with Count Vectorizer \n",
    "\n",
    "grid.fit(X_train_cvec, y_train_cvec)\n",
    "\n",
    "grid.best_score_\n",
    "# best cross val score achived\n",
    "\n",
    "grid.best_params_\n",
    "\n",
    "#### Logistic Regression Best Parameters for Count vectorizer \n",
    "\n",
    "best_lr_cvec = grid.best_estimator_\n",
    "# referenec to the model with the best score \n",
    "best_lr_cvec\n",
    "\n",
    "best_lr_cvec.score(X_test_cvec, y_test_cvec)\n",
    "\n",
    "#### Logistic Regression Best Parameters for TFIDF\n",
    "\n",
    "grid.fit(X_train_tvec, y_train_tvec)\n",
    "\n",
    "\n",
    "grid.best_score_\n",
    "\n",
    "grid.best_params_\n",
    "\n",
    "#### Using best Params\n",
    "\n",
    "best_lr_tvec = grid.best_estimator_\n",
    "best_lr_tvec \n",
    "\n",
    "best_lr_tvec.score(X_test_tvec, y_test_tvec)\n",
    "\n",
    "Logistic regression is a classifier which measures the accuracy score to determine..... You can see that TFIFD had the better score so this is the Feature Transformer that I will be choosing for my test set \n",
    "\n",
    "Count vectorizer best estimators score = 0.7782258064516129\n",
    "C=1.0,\n",
    "\n",
    "TFIFD best estimators score = 0.7903225806451613\n",
    "C=10.0, \n",
    "\n",
    "## Params on testing data\n",
    "- TFDIF was fitted on the training data which will be used to transfomation the words in testing into a sparse matrix\n",
    "- This will then use the logistic regressions best parameters which were fit for thr training data to predict sentiment/ y_hat for my testing data.\n",
    "\n",
    "\n",
    "testing.head(3)\n",
    "\n",
    "# transform the testing data\n",
    "X_test_testing = tvec.transform(testing.words)\n",
    "\n",
    "# predictions and predictive probabilities\n",
    "y_hat = best_lr_tvec.predict(X_test_testing)\n",
    "y_hat_pp = best_lr_tvec.predict_proba(X_test_testing)\n",
    "y_hat_pp\n",
    "\n",
    "logistic regression gave a good score in classifying the predictors but will try different classifiers to determine best accuracy score \n",
    "\n",
    "best_lr_tvec\n",
    "\n",
    "## next\n",
    "- Should i try a different approach by grid searching the vectorisers to see which ones perform best rather than the classifier?? \n",
    "- next steps are to loop through a list of classifiers choose the best one/s performing then grid search in a pipline with the vectoriser to optimise both params\n",
    "\n",
    "# GridSearch Chosen Estimators\n",
    "- TFIDF transformer\n",
    "- SGDClassifer\n",
    "- Random Forest\n",
    "'RandomForestClassifier': RandomForestClassifier()\n",
    "\n",
    "\n",
    "X_train\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "SGDC_pipeline = Pipeline([('tfidf', TfidfVectorizer()),('SGDC', SGDClassifier())])\n",
    "    \n",
    "SGDC_parameters = {\n",
    "     'vect__max_features': (None, 5000, 10000, 50000),\n",
    "#     'tfidf__max_features': (None, 500, 1000, 1500),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'SGDC__loss': ['squared_loss'],#'huber'],\n",
    "    'SGDC__penalty': ['l1','l2', 'elasticnet'],\n",
    "    'SGDC__alpha': np.logspace(-5,1,15)}\n",
    "\n",
    "\n",
    "# SGDC_pipeline.fit(X_train,y_train)\n",
    "\n",
    "# SGDC_grid_search_tune = GridSearchCV(SGDC_pipeline, param_grid = SGDC_parameters, cv=5, n_jobs=2, verbose=3, )\n",
    "# SGDC_grid_search_tune.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print SGDC_grid_search_tune.best_estimator_\n",
    "\n",
    "# we define the gridsearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "#### we fit it\n",
    "grid_search.fit(data.data, data.target)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "#### get the best parameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Chosen Estimators\n",
    "- TFIDF transformer\n",
    "- SGDClassifer\n",
    "- Random Forest\n",
    "'RandomForestClassifier': RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1157x1856 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 9345 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "SGDC_pipeline = Pipeline([('tfidf', TfidfVectorizer()),('SGDC', SGDClassifier())])\n",
    "    \n",
    "SGDC_parameters = {\n",
    "     'vect__max_features': (None, 5000, 10000, 50000),\n",
    "#     'tfidf__max_features': (None, 500, 1000, 1500),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'SGDC__loss': ['squared_loss'],#'huber'],\n",
    "    'SGDC__penalty': ['l1','l2', 'elasticnet'],\n",
    "    'SGDC__alpha': np.logspace(-5,1,15)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGDC_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGDC_grid_search_tune = GridSearchCV(SGDC_pipeline, param_grid = SGDC_parameters, cv=5, n_jobs=2, verbose=3, )\n",
    "# SGDC_grid_search_tune.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters:\")\n",
    "print SGDC_grid_search_tune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we define the gridsearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "#### we fit it\n",
    "grid_search.fit(data.data, data.target)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "#### get the best parameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Random Forest Classifer\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {'n_estimators':[10,20,30],\n",
    "             'criterion': ('gini'\n",
    "             'max_depth':[1,2,3,4,5,6],\n",
    "            'max_features':[1,2,3,4], \n",
    "            'max_leaf_nodes':[5,6,7,8,9,10], \n",
    "            'min_samples_leaf':[1,2,3,4],\n",
    "            'min_samples_split':[2,3,4]}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, param_grid=rf_params, cv=5, n_jobs=-1, verbose=1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# best score on the training data:\n",
    "rf_grid.best_score_\n",
    "\n",
    "# best parameters on the training data:\n",
    "features??rf_grid.best_params_## SGDClassifier\n",
    "\n",
    "sklearn.linear_model.SGDClassifier()\n",
    "\n",
    "'SGDC__alpha': (0.00001, 0.000001 'clf__alpha': (1.0000000000000001e-05, 9.9999999999999995e-07)\n",
    "'SGDC__penalty': ('l2', 'elasticnet'),\n",
    "'SGDC__n_iter': (10, 50, 80)}\n",
    "\n",
    "- loss : str, ‘hinge’ or ‘log’ or ‘modified_huber’\n",
    "The loss function to be used. Defaults to ‘hinge’. The hinge loss is a margin loss used by standard linear SVM models. The ‘log’ loss is the loss of logistic regression models and can be used for probability estimation in binary classifiers. ‘modified_huber’ is another smooth loss that brings tolerance to outliers.\n",
    "\n",
    "- penalty : str, ‘l2’ or ‘l1’ or ‘elasticnet’\n",
    "The penalty (aka regularization term) to be used. Defaults to ‘l2’ which is the standard regularizer for linear SVM models. ‘l1’ and ‘elasticnet’ migh bring sparsity to the model (feature selection) not achievable with ‘l2’.\n",
    "\n",
    "- alpha : float\n",
    "Constant that multiplies the regularization term. Defaults to 0.0001\n",
    "\n",
    "- rho : float\n",
    "The Elastic Net mixing parameter, with 0 < rho <= 1. Defaults to 0.85.\n",
    "\n",
    "- fit_intercept: bool :\n",
    "Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.\n",
    "\n",
    "- n_iter: int, optional :\n",
    "The number of passes over the training data (aka epochs). Defaults to 5.\n",
    "\n",
    "- shuffle: bool, optional :\n",
    "Whether or not the training data should be shuffled after each epoch. Defaults to False.\n",
    "\n",
    "- seed: int, optional:\n",
    "The seed of the pseudo random number generator to use when shuffling the data.\n",
    "\n",
    "- learning_rate : string, optional\n",
    "The learning rate: constant: eta = eta0 optimal: eta = 1.0/(t+t0) [default] invscaling: eta = eta0 / pow(t, power_t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 343 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 843 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1543 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2443 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3543 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4843 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6343 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8043 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8633 out of 8640 | elapsed:  2.8min remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 8640 out of 8640 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [1, 2, 3, 4], 'max_leaf_nodes': [5, 6, 7, 8, 9, 10], 'min_samples_split': [2, 3, 4], 'max_depth': [1, 2, 3, 4, 5, 6], 'min_samples_leaf': [1, 2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_params = {'n_estimators':[10,20,30],\n",
    "             'criterion': ('gini'\n",
    "             'max_depth':[1,2,3,4,5,6],\n",
    "            'max_features':[1,2,3,4], \n",
    "            'max_leaf_nodes':[5,6,7,8,9,10], \n",
    "            'min_samples_leaf':[1,2,3,4],\n",
    "            'min_samples_split':[2,3,4]}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, param_grid=rf_params, cv=5, n_jobs=-1, verbose=1)\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286084701815039"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score on the training data:\n",
    "rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_features': 3,\n",
       " 'max_leaf_nodes': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters on the training data:\n",
    "features??rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.linear_model.SGDClassifier()\n",
    "\n",
    "'SGDC__alpha': (0.00001, 0.000001 'clf__alpha': (1.0000000000000001e-05, 9.9999999999999995e-07)\n",
    "'SGDC__penalty': ('l2', 'elasticnet'),\n",
    "'SGDC__n_iter': (10, 50, 80)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loss : str, ‘hinge’ or ‘log’ or ‘modified_huber’\n",
    "The loss function to be used. Defaults to ‘hinge’. The hinge loss is a margin loss used by standard linear SVM models. The ‘log’ loss is the loss of logistic regression models and can be used for probability estimation in binary classifiers. ‘modified_huber’ is another smooth loss that brings tolerance to outliers.\n",
    "\n",
    "- penalty : str, ‘l2’ or ‘l1’ or ‘elasticnet’\n",
    "The penalty (aka regularization term) to be used. Defaults to ‘l2’ which is the standard regularizer for linear SVM models. ‘l1’ and ‘elasticnet’ migh bring sparsity to the model (feature selection) not achievable with ‘l2’.\n",
    "\n",
    "- alpha : float\n",
    "Constant that multiplies the regularization term. Defaults to 0.0001\n",
    "\n",
    "- rho : float\n",
    "The Elastic Net mixing parameter, with 0 < rho <= 1. Defaults to 0.85.\n",
    "\n",
    "- fit_intercept: bool :\n",
    "Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.\n",
    "\n",
    "- n_iter: int, optional :\n",
    "The number of passes over the training data (aka epochs). Defaults to 5.\n",
    "\n",
    "- shuffle: bool, optional :\n",
    "Whether or not the training data should be shuffled after each epoch. Defaults to False.\n",
    "\n",
    "- seed: int, optional:\n",
    "The seed of the pseudo random number generator to use when shuffling the data.\n",
    "\n",
    "- learning_rate : string, optional\n",
    "The learning rate: constant: eta = eta0 optimal: eta = 1.0/(t+t0) [default] invscaling: eta = eta0 / pow(t, power_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "#     'SVC': SVC(),\n",
    "#     'MultinomialNB': MultinomialNB(),\n",
    "#     'SGDClassifier': SGDClassifier()\n",
    "    \n",
    "#     'KNeighborsClassifier':{'n_neighbors':[1,3,5,9,15,21], 'weights':['uniform','distance'],\n",
    "#                             'metric':['euclidean','manhattan'],parameter_grid = {\n",
    "#                     'n_neighbors':range(1,151), 'weights':['uniform','distance',custom_function],\n",
    "#                     'algorithm':['ball_tree','kd_tree','brute','auto'],'leaf_size':range(1,152),\n",
    "#                         'metric':['minkowski','euclidean'], 'p':[1,2]\n",
    "    \n",
    "#     'SVC': [{'kernel': ['linear'], 'C': [1, 10]},\n",
    "#             {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]}\n",
    "\n",
    "#     'MultinomialNB': MultinomialNB(),\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Extra notes for NLP\n",
    "\n",
    "\n",
    "#### Count vectoriser parameters \n",
    "ngram_ra,nge=(2,2), token_pattern='\\w+', \n",
    "- stop words remove common words that are commonly found which hold no deeper meaning to the context of the text.so, will not be used\n",
    "\n",
    "- token pattern = \\w+?????\n",
    "\n",
    "- ngram_range= (2,2)this represent the string of words in a row. \n",
    "\n",
    "- max_features=200????\n",
    "- min_df=0, \n",
    "- charset_error=\"ignore\"\n",
    "\n",
    "The data then fit and transformed to the \n",
    "\n",
    "stop_words: Since CountVectorizer just counts the occurrences of each word in its vocabulary, extremely common words like ‘the’, ‘and’, etc. will become very important features while they add little meaning to the text. Your model can often be improved if you don’t take those words into account. Stop words are just a list of words you don’t want to use as features. You can set the parameter stop_words=’english’ to use a built-in list. Alternatively you can set stop_words equal to some custom list. This parameter defaults to None.\n",
    "ngram_range: An n-gram is just a string of n words in a row. E.g. the sentence ‘I am Groot’ contains the 2-grams ‘I am’ and ‘am Groot’. The sentence is itself a 3-gram. Set the parameter ngram_range=(a,b) where a is the minimum and b is the maximum size of ngrams you want to include in your features. The default ngram_range is (1,1).\n",
    "In a recent project where I modeled job postings online, I found that including 2-grams as features boosted my model’s predictive power significantly. This makes intuitive sense; many job titles such as ‘data scientist’, ‘data engineer’, and ‘data analyst’ are 2 words long.\n",
    "min_df, max_df: These are the minimum and maximum document frequencies words/n-grams must have to be used as features. If either of these parameters are set to integers, they will be used as bounds on the number of documents each feature must be in to be considered as a feature. If either is set to a float, that number will be interpreted as a frequency rather than a numerical limit. min_df defaults to 1 (int) and max_df defaults to 1.0 (float).\n",
    "max_features: This parameter is pretty self-explanatory. The CountVectorizer will choose the words/features that occur most frequently to be in its’ vocabulary and drop everything else.\n",
    "You would set these parameters when initializing your CountVectorizer object as shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
