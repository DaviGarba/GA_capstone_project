{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  Training and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:\n",
    "- polarity : Target 2:positive, 1:neutral, 0:negative\n",
    "- words : preprocessed sentences\n",
    "- type : the tags of the words from lemmatizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words    1\n",
      "type     1\n",
      "dtype: int64\n",
      "words       1\n",
      "type        1\n",
      "polarity    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>type</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words type  polarity\n",
       "747   NaN  NaN       2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.read_csv('./clean_data/testing_data.csv', encoding='utf8')\n",
    "print testing.isnull().sum()\n",
    "testing[testing.words.isnull()]\n",
    "training = pd.read_csv('./clean_data/training_data.csv', encoding='utf8')\n",
    "print training.isnull().sum()\n",
    "training[training.words.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:\n",
    "- polarity : Target 2:positive, 1:neutral, 0:negative\n",
    "- words : preprocessed sentences\n",
    "- type : the tags of the words from lemmatizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I was loading the data I found that there were null values appearing. When referring back, these values came from the cleaning process and were converted to Null values when they were saved to csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words       0\n",
      "type        0\n",
      "polarity    0\n",
      "dtype: int64\n",
      "words    0\n",
      "type     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testing = testing.dropna()\n",
    "training = training.dropna()\n",
    "print training.isnull().sum()\n",
    "print testing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>type</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>judge previous post used be good place not longer</td>\n",
       "      <td>VB JJ NN VB VB JJ NN RB JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be arrive noon place be empty staff act be imp...</td>\n",
       "      <td>VB VB NN NN VB JJ NN VB VB VB VB RB JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>never bring complimentary noodle ignore repeat...</td>\n",
       "      <td>RB VB JJ NN VB JJ NN NN VB NN NN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food be lousy too sweet too salty portion tiny</td>\n",
       "      <td>NN VB JJ RB JJ RB JJ NN JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food be lousy too sweet too salty portion tiny</td>\n",
       "      <td>NN VB JJ RB JJ RB JJ NN JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  \\\n",
       "0  judge previous post used be good place not longer   \n",
       "1  be arrive noon place be empty staff act be imp...   \n",
       "2  never bring complimentary noodle ignore repeat...   \n",
       "3     food be lousy too sweet too salty portion tiny   \n",
       "4     food be lousy too sweet too salty portion tiny   \n",
       "\n",
       "                                     type  polarity  \n",
       "0              VB JJ NN VB VB JJ NN RB JJ       0.0  \n",
       "1  VB VB NN NN VB JJ NN VB VB VB VB RB JJ       0.0  \n",
       "2        RB VB JJ NN VB JJ NN NN VB NN NN       0.0  \n",
       "3              NN VB JJ RB JJ RB JJ NN JJ       0.0  \n",
       "4              NN VB JJ RB JJ RB JJ NN JJ       0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split \n",
    "- The use of a Train Test Split is to test how well our classifier is working for predicitons.\n",
    "\n",
    "https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 \n",
    "\n",
    "------ look up stratified..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# predictor\n",
    "X = training.words\n",
    "# target\n",
    "y = training.polarity\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline of Model\n",
    "- The baseline accuracy is the proportion of the majority class. In this case '2' which is positive sentiment and so the baseline accuracy is 0.724138\n",
    "\n",
    "baseline_accuracy = majority class N / total N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    0.724138\n",
      "0.0    0.243799\n",
      "1.0    0.032063\n",
      "Name: polarity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print y.value_counts(normalize=True)\n",
    "\n",
    "baseline = 0.724138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation for Training Data\n",
    "- Count Vectorizer and TFIDF Vectorizer are both are used to compare the best fitting thus, choosing which transformer is best aporopriate.\n",
    "- Logistic Regression is the classifier used to measure this. \n",
    "Logistic regression is a very fast classifier???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Count Vectorizer on Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# initalise the vectoriser \n",
    "cvec = CountVectorizer()\n",
    "# fit the training data on the model\n",
    "cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform training data into sparse matrix\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)\n",
    "\n",
    "# fit with Logistic Regression\n",
    "lr.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with LR\n",
    "y_pred_cvec = lr.predict(X_test_cvec)\n",
    "cvec_score  = accuracy_score(y_test, y_pred_cvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have the same number of rows but the vectorization has converted every word, or what is believed to be a word, from our test data into a feature. This is like dummy coded variables for words except that we have counts rather than just occurances.???.... featured names of wueds frequency of the top highest words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COUNT VEC - Word Frequency \n",
    "matrix outputting the 10 most common words and how many times they appear \n",
    "- Feature matrix of word occurences \n",
    "- top 10 word most occuring words\n",
    "- most important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cvec = pd.DataFrame(cvec_mat.todense(),columns=cvec.get_feature_names())\n",
    "word_freq = df_cvec.sum(axis=0).sort_values(ascending=False)[:10]\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COUNT VEC - Zipf's law\n",
    "It state that \n",
    "In a corpus of text, any words frequency is inversely proportional to its rank in the frequency table. \n",
    "\n",
    "Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.: the rank-frequency distribution is an inverse relation\n",
    "\n",
    "\n",
    "Unsurprisingly, the word frequencies for the collected works of Alexandre Dumas appear to follow the predictions made by Zipf’s law! In this blog post, I’ll show you how to use bash and R to perform this simple analysis.\n",
    "\n",
    "\n",
    "Plotting the word frequency distribution, we observe : what is thissssssssss? https://en.wikipedia.org/wiki/Zipf%27s_law "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# word_freq.plot(kind='hist',\n",
    "#             title='Number of words with a given number of appearances',\n",
    "#             fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdF (term frequency inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# initalise the vectoriser \n",
    "tvec = TfidfVectorizer()\n",
    "# fit the training data on the model\n",
    "tvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annabopeep/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform training data into sparse matrix\n",
    "X_train_tvec = tvec.transform(X_train)\n",
    "X_test_tvec = tvec.transform(X_test)\n",
    "\n",
    "# fit with Logistic Regression\n",
    "lr.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with LR\n",
    "y_pred_tvec = lr.predict(X_test_tvec)\n",
    "tvec_score  = accuracy_score(y_test, y_pred_tvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing scores\n",
    "- Both vectorizers increased the accuracy\n",
    "- TFIFD has the highest so is the chosen Feature Transformer that I will be choosing for my test set \n",
    "\n",
    "Hyperparameters will also be tested for the transformer\n",
    "Both sparse matrices from the feature transformers (count vectoriser and TFIDF) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.724138\n",
      "count vectorizer score: 0.7782258064516129\n",
      "tfidf vectorizer score: 0.780241935483871\n"
     ]
    }
   ],
   "source": [
    "print 'baseline:', baseline\n",
    "print 'count vectorizer score:', cvec_score\n",
    "print 'tfidf vectorizer score:', tvec_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIFD Vectorizer Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (term frequency–inverse document frequency)is a calculation to transform words into numbers. It takes into account the frequecy of a word in a given document and the frequency between documents. So if a term is common in most documents it is supressed and rare words  are given more influence showing they are highly specific for a particular document. \n",
    "\n",
    "To break it down:\n",
    "Term Frequency: More frequent terms in a target article, the higher the score\n",
    "Inverse Document Frequency: The more common in other articles, the lower the score\n",
    "\n",
    "Mathematically, the importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.\n",
    "\n",
    "TFcalculationformuala...\n",
    "$$\n",
    "\\mathrm{idf}(t, D) = 1+\\log\\left(\\frac{1+N_\\text{Documents}}{1+N_\\text{Documents that contain term}}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{tf-idf}(t,d,D) = \\mathrm{tf}(t,d) \\cdot \\mathrm{idf}(t, D)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.724138\n",
      "Default Params: 0.780241935483871\n",
      "Optimal Params: 0.7903225806451613\n",
      "Number of features: 1626\n"
     ]
    }
   ],
   "source": [
    "# new params for tfifd and fit to training\n",
    "tvec_p = TfidfVectorizer(max_features=900, norm=None)\n",
    "tvec_p.fit(X_train)\n",
    "\n",
    "# transform to train and test \n",
    "X_train_tvec_p = tvec_p.transform(X_train)\n",
    "X_test_tvec_p = tvec_p.transform(X_test)\n",
    "\n",
    "# fit to LR, predict and score\n",
    "lr.fit(X_train_tvec_p, y_train)\n",
    "y_pred = lr.predict(X_test_tvec_p)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print 'Baseline:', baseline\n",
    "print 'Default Params:', tvec_score\n",
    "print 'Optimal Params:', score\n",
    "print \"Number of features:\", len(tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.7883064516129032 max features\n",
    "0.7903225806451613 + norm none\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose parameters improve our analysis. There are some which can be applied but will not be used because the preprocessing step included them including stop words, lowercase and tokenizer. We will include parameters under a range which will be Grid Searched to give the optimal scores for the specific model in the pipeline. \n",
    "\n",
    "Parameters help show us how exactly we want to break down the document.\n",
    "\n",
    "- max_features : \n",
    "The maxiumum number of highest term frequencies across the corpus will only be considered as the vocabulary. \n",
    "- norm : (‘l1’, ‘l2’, None)????\n",
    "Norm used to normalize term vectors. None for no normalization.\n",
    "\n",
    "\n",
    "- ngram_range :(min_n, max_n) i should only use this if on raw text????\n",
    "The n-value range of lower and upper boundaries for n-grams to be extracted.\n",
    "- min_df \n",
    "specifies that a word must be used at least twice to be considered. In practice this is useful for removing things like URLs from text, which appear as one offs.\n",
    "\n",
    "- The max_df is a float value — this tell the vectorizer to ignore words which appears in more than 50% of documents in the corpus. This generally catches words not already defined in the stopwords set.\n",
    "\n",
    "- We also define a set of stop words. These are words like “a” or “is” which appear so often in a language that we know they won’t provide useful information and so can be ignored.\n",
    "\n",
    "\n",
    "\n",
    "http://apapiu.github.io/2016-08-04-tf_idf/\n",
    "\n",
    "- Finally we use fit_transform() to train the vectorizer using the corpus we defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sublinear_tf=True, max_features = 500 \n",
    "\n",
    "max_features : int or None, default=None\n",
    "    If not None, build a vocabulary that only consider the top\n",
    "    max_features ordered by term frequency across the corpus.\n",
    "\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "sublinear_tf : boolean, default=False\n",
    "    Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "TF-IDF: combination of sublinear TF and inverse document frequency???\n",
    "\n",
    "Term Frequency (TF)\n",
    "local frequency of a word in the document\n",
    "i.e. the word is weighed by how many times it occurs in the document\n",
    "tf(w,d)=∣∣{w′∈d : w′=w}∣∣tf(w,d)=|{w′∈d : w′=w}| where ww is a word and d={w1, ... ,wm}d={w1, ... ,wm} is a document\n",
    "\n",
    "Sublinear TF:\n",
    "sometimes a word is used too often so we want to reduce its influence compared to other less frequently used words\n",
    "for that we can use some sublinear function, e.g.\n",
    "logtf(w,d)log⁡tf(w,d) or tf(w,d)‾‾‾‾‾‾‾√\n",
    "\n",
    "http://0agr.ru/wiki/index.php/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_df  = pd.DataFrame(tvec.transform(training.words).todense(),\n",
    "                   columns=tvec.get_feature_names())\n",
    "tvec_df.sum(axis=0).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params on testing data\n",
    "- TFDIF was fitted on the training data which will be used to transfomation the words in testing into a sparse matrix\n",
    "- This will then use the logistic regressions best parameters which were fit for thr training data to predict sentiment/ y_hat for my testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the testing data\n",
    "X_test_testing = tvec.transform(testing.words)\n",
    "\n",
    "# predictions and predictive probabilities\n",
    "y_hat = best_lr_tvec.predict(X_test_testing)\n",
    "y_hat_pp = best_lr_tvec.predict_proba(X_test_testing)\n",
    "y_hat_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression gave a good score in classifying the predictors but will try different classifiers to determine best accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_lr_tvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## next\n",
    "- Should i try a different approach by grid searching the vectorisers to see which ones perform best rather than the classifier?? \n",
    "- next steps are to loop through a list of classifiers choose the best one/s performing then grid search in a pipline with the vectoriser to optimise both params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
