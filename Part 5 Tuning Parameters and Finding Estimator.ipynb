{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  Training and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:\n",
    "- polarity : Target 2:positive, 1:neutral, 0:negative\n",
    "- words : preprocessed sentences\n",
    "- type : the tags of the words from lemmatizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('./clean_data/training_data.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>type</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>judge previous post used be good place not longer</td>\n",
       "      <td>VB JJ NN VB VB JJ NN RB JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be arrive noon place be empty staff act be imp...</td>\n",
       "      <td>VB VB NN NN VB JJ NN VB VB VB VB RB JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>never bring complimentary noodle ignore repeat...</td>\n",
       "      <td>RB VB JJ NN VB JJ NN NN VB NN NN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food be lousy too sweet too salty portion tiny</td>\n",
       "      <td>NN VB JJ RB JJ RB JJ NN JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food be lousy too sweet too salty portion tiny</td>\n",
       "      <td>NN VB JJ RB JJ RB JJ NN JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  \\\n",
       "0  judge previous post used be good place not longer   \n",
       "1  be arrive noon place be empty staff act be imp...   \n",
       "2  never bring complimentary noodle ignore repeat...   \n",
       "3     food be lousy too sweet too salty portion tiny   \n",
       "4     food be lousy too sweet too salty portion tiny   \n",
       "\n",
       "                                     type  polarity  \n",
       "0              VB JJ NN VB VB JJ NN RB JJ       0.0  \n",
       "1  VB VB NN NN VB JJ NN VB VB VB VB RB JJ       0.0  \n",
       "2        RB VB JJ NN VB JJ NN NN VB NN NN       0.0  \n",
       "3              NN VB JJ RB JJ RB JJ NN JJ       0.0  \n",
       "4              NN VB JJ RB JJ RB JJ NN JJ       0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = training.dropna()\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = training.words\n",
    "y = training.polarity\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer(max_features=900, norm=None)\n",
    "tvec.fit(X_train)\n",
    "\n",
    "#transformed matrix of words\n",
    "X_train_tvec = tvec.transform(X_train)\n",
    "X_test_tvec = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding an Estimator\n",
    "- Choosing an estimator which will perform at its optimum so can be tuned further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.7903225806451613\n",
      "______________________________________________________________________\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.7641129032258065\n",
      "______________________________________________________________________\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.7721774193548387\n",
      "______________________________________________________________________\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "0.7620967741935484\n",
      "______________________________________________________________________\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.7600806451612904\n",
      "______________________________________________________________________\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "0.7782258064516129\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(),\n",
    "          RandomForestClassifier(),\n",
    "          SVC(),\n",
    "          KNeighborsClassifier(), \n",
    "          MultinomialNB(), \n",
    "          SGDClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    print model\n",
    "    \n",
    "    model.fit(X_train_tvec, y_train)\n",
    "    y_pred = model.predict(X_test_tvec)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print score\n",
    "    print '_'*70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With limited time I have chosen a localised method to choose my classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch using Tfidf optimal parameters \n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "\n",
    "Grid Search CV Logistic Regression\n",
    "Logistic regression is a very fast classifier.\n",
    "I am using grid search to find best hyperparameters.\n",
    "random_state=1 lr param fixed random... for l1 l2 ???????\n",
    "\n",
    "For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used??? arguement?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   17.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([1.e-10, 1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03,\n",
       "       1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
       "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=1)\n",
    "lr_params = {'penalty': ['l1','l2'],\n",
    "          'solver':['liblinear'],\n",
    "          'C': np.logspace(-10,10,21)}\n",
    "\n",
    "lr_grid = GridSearchCV(lr, param_grid=lr_params, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# fit with the tranformed tfidf matrix as X\n",
    "lr_grid.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8107173725151253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score on the training data:\n",
    "print lr_grid.best_score_\n",
    "\n",
    "# assign the best estimator to a variable:\n",
    "best_lr = lr_grid.best_estimator_\n",
    "\n",
    "# best parameters on the training data:\n",
    "lr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2 is ridgeeeeeeee\n",
    "# Lasso was chosen: this indicates that maybe unimportant (noise) variables\n",
    "# is more of an issue in our data than multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7883064516129032"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score it on the testing data:\n",
    "best_lr.score(X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "X_train_tvec, y_train\n",
    "\n",
    "lr_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classification errors: 193.0\n"
     ]
    }
   ],
   "source": [
    "print \"Number of classification errors:\", np.abs(y_pred_lr - y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = best_lr.predict(X_test_tvec)\n",
    "y_pp_lr = best_lr.predict_proba(X_test_tvec)\n",
    "\n",
    "\n",
    "# Get the predicted probability vector and explicitly name the columns:\n",
    "Y_pp = pd.DataFrame(knn.predict_proba(X_test_tvec), columns=['class_0_pp','class_1_pp'])\n",
    "Y_pp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60,   2,  59],\n",
       "       [  4,   2,  10],\n",
       "       [ 29,   1, 329]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7883064516129032\n",
      "0.19047619047619047\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(y_test,y_pred_lr) # same as above accuracy\n",
    "# print precision_score(y_test,y_pred_lr)\n",
    "# print recall_score(y_test,y_pred_lr)\n",
    "print f1_score(y_test==1, y_pred_lr==1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.50      0.56       121\n",
      "        1.0       0.40      0.12      0.19        16\n",
      "        2.0       0.83      0.92      0.87       359\n",
      "\n",
      "avg / total       0.77      0.79      0.77       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's analyse the features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.556775</td>\n",
       "      <td>0.556775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.474660</td>\n",
       "      <td>0.474660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>-0.468406</td>\n",
       "      <td>0.468406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>-0.456145</td>\n",
       "      <td>0.456145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-0.451457</td>\n",
       "      <td>0.451457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef  abs_coef\n",
       "471  0.556775  0.556775\n",
       "343  0.474660  0.474660\n",
       "322 -0.468406  0.468406\n",
       "609 -0.456145  0.456145\n",
       "210 -0.451457  0.451457"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "        'coef':best_lr.coef_[0]})\n",
    "coef_df['abs_coef'] = np.abs(coef_df.coef)\n",
    "# sort by absolute value of coefficient (magnitude)\n",
    "coef_df.sort_values('abs_coef', ascending=False, inplace=True)\n",
    "\n",
    "coef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show non-zero coefs and predictors\n",
    "# coef_df[coef_df.coef != 0]\n",
    "len(coef_df[coef_df.coef != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data\n",
    "    - polarity : Target 2:positive, 1:neutral, 0:negative\n",
    "    - words : preprocessed sentences\n",
    "    - type : the tags of the words from lemmatizing \n",
    "\n",
    "\n",
    "TFDIF was fitted on the training data which will be used to transfomation the words in testing into a sparse matrix\n",
    "Logistic Regressions best parameters which were fit for the training data will then predict sentiment (y_hat) for the transformed testing data.\n",
    "\n",
    "\n",
    "\n",
    "---- logistic regression gave a good score in classifying the predictors but will try different classifiers to determine best accuracy score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('./clean_data/testing_data.csv', encoding='utf8')\n",
    "testing = testing.dropna()\n",
    "X = testing.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00474512, 0.00256113, 0.99269375],\n",
       "       [0.48790896, 0.09569509, 0.41639595],\n",
       "       [0.78429316, 0.03728551, 0.17842134],\n",
       "       ...,\n",
       "       [0.28897808, 0.0186247 , 0.69239723],\n",
       "       [0.28897808, 0.0186247 , 0.69239723],\n",
       "       [0.28897808, 0.0186247 , 0.69239723]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the testing data\n",
    "X_mat = tvec.transform(X)\n",
    "\n",
    "# predictions and predictive probabilities\n",
    "y_hat = best_lr.predict(X_mat)\n",
    "y_hat_pp = best_lr.predict_proba(X_mat)\n",
    "y_hat_pp\n",
    "\n",
    "# probability in class 1 class 2 class 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "\n",
    "https://stackoverflow.com/questions/40679883/scikit-learn-how-to-include-others-features-after-performed-fit-and-transform-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression performs best out of the two classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "- boostrap\n",
    "- switch vectoriser and train test split \n",
    "- chek models again!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "later, additonal work, \n",
    "- clustering\n",
    "whats similar to logistic regression\n",
    "-neural networks\n",
    "from sklearn.neural_network import MLPClassifier "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
