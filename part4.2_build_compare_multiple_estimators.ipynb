{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 Build Multiple Estimators\n",
    "Some of the steps we will take to build a model include:\n",
    "- Selecting the appropriate model\n",
    "- Building a model\n",
    "- Testing and training our model\n",
    "- Evaluating and refining our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:\n",
    "- polarity : Target 2:positive, 1:neutral, 0:negative\n",
    "- words : preprocessed sentences\n",
    "- type : the tags of the words from lemmatizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lem_words</th>\n",
       "      <th>lem_tags</th>\n",
       "      <th>word_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Next time, we wouldn't dare ordering anything ...</td>\n",
       "      <td>1</td>\n",
       "      <td>next time wouldn dare order anything else othe...</td>\n",
       "      <td>JJ NN VB VB VB NN RB JJ JJ NN NN NN</td>\n",
       "      <td>[next/JJ, time/NN, wouldn/VB, dare/VB, order/V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's the difference between the two?</td>\n",
       "      <td>1</td>\n",
       "      <td>difference</td>\n",
       "      <td>NN</td>\n",
       "      <td>[difference/NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downtown Dinner 2002 - Prixe fix: Appetizers w...</td>\n",
       "      <td>1</td>\n",
       "      <td>downtown dinner fix appetizer be waiter give p...</td>\n",
       "      <td>JJ NN VB NN VB NN VB JJ NN VB NN NN VB RB</td>\n",
       "      <td>[downtown/JJ, dinner/NN, fix/VB, appetizer/NN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wasn't thrilled to have to wait on line for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wasn thrill have wait line minute guess price ...</td>\n",
       "      <td>VB VB VB VB NN NN NN NN VB JJ NN</td>\n",
       "      <td>[wasn/VB, thrill/VB, have/VB, wait/VB, line/NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We were fast to order the appetizer platter si...</td>\n",
       "      <td>1</td>\n",
       "      <td>be fast order appetizer platter be very hungry</td>\n",
       "      <td>VB JJ NN NN JJ VB RB JJ</td>\n",
       "      <td>[be/VB, fast/JJ, order/NN, appetizer/NN, platt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment  \\\n",
       "0  Next time, we wouldn't dare ordering anything ...          1   \n",
       "1             What's the difference between the two?          1   \n",
       "2  Downtown Dinner 2002 - Prixe fix: Appetizers w...          1   \n",
       "3  I wasn't thrilled to have to wait on line for ...          1   \n",
       "4  We were fast to order the appetizer platter si...          1   \n",
       "\n",
       "                                           lem_words  \\\n",
       "0  next time wouldn dare order anything else othe...   \n",
       "1                                         difference   \n",
       "2  downtown dinner fix appetizer be waiter give p...   \n",
       "3  wasn thrill have wait line minute guess price ...   \n",
       "4     be fast order appetizer platter be very hungry   \n",
       "\n",
       "                                    lem_tags  \\\n",
       "0        JJ NN VB VB VB NN RB JJ JJ NN NN NN   \n",
       "1                                         NN   \n",
       "2  JJ NN VB NN VB NN VB JJ NN VB NN NN VB RB   \n",
       "3           VB VB VB VB NN NN NN NN VB JJ NN   \n",
       "4                    VB JJ NN NN JJ VB RB JJ   \n",
       "\n",
       "                                           word_tags  \n",
       "0  [next/JJ, time/NN, wouldn/VB, dare/VB, order/V...  \n",
       "1                                    [difference/NN]  \n",
       "2  [downtown/JJ, dinner/NN, fix/VB, appetizer/NN,...  \n",
       "3  [wasn/VB, thrill/VB, have/VB, wait/VB, line/NN...  \n",
       "4  [be/VB, fast/JJ, order/NN, appetizer/NN, platt...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv('./train_test_data/training_bs.csv', encoding='utf8')\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = training['lem_words']\n",
    "y_train = training['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.333333\n",
      "2    0.333333\n",
      "0    0.333333\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print y_train.value_counts(normalize=True)\n",
    "baseline = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation for Training Data\n",
    "- random state to keep consistent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "lr = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer and Tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initalise the vectoriser \n",
    "cvec = CountVectorizer()\n",
    "cvec.fit(X_train)\n",
    "#transform training data into sparse matrix\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# initalise the vectoriser \n",
    "tvec = TfidfVectorizer()\n",
    "# fit the training data on the model\n",
    "tvec.fit(X_train)\n",
    "\n",
    "#transform training data into sparse matrix\n",
    "X_train_tvec = tvec.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding an Estimator \n",
    "- Choosing an estimator which will perform at its optimum so can be tuned further.\n",
    "- using both vectorisers to see which ones work best with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "count vectoriser: 0.8954330270119742\n",
      "tfidf vectoriser: 0.8562683237431906\n",
      "______________________________________________________________________\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "count vectoriser: 0.8958303999699623\n",
      "tfidf vectoriser: 0.8954126890259356\n",
      "______________________________________________________________________\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "count vectoriser: 0.8937746989195836\n",
      "tfidf vectoriser: 0.9075137907189946\n",
      "______________________________________________________________________\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "count vectoriser: 0.4025356775208933\n",
      "tfidf vectoriser: 0.6479885731807671\n",
      "______________________________________________________________________\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "count vectoriser: 0.7320845809905538\n",
      "tfidf vectoriser: 0.7491637958817142\n",
      "______________________________________________________________________\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "count vectoriser: 0.8370942962900384\n",
      "tfidf vectoriser: 0.8420943119346432\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(),\n",
    "          RandomForestClassifier(),\n",
    "          SGDClassifier(),\n",
    "          SVC(),\n",
    "          KNeighborsClassifier(), \n",
    "          MultinomialNB()\n",
    "          ]\n",
    "\n",
    "scores_cvec = []\n",
    "scores_tvec = []\n",
    "for model in models:\n",
    "    print model\n",
    "    \n",
    "    score_cvec = cross_val_score(model, X_train_cvec, y_train, cv=3).mean()\n",
    "    score_tvec = cross_val_score(model, X_train_tvec, y_train, cv=3).mean()\n",
    "    \n",
    "    print 'count vectoriser:', score_cvec\n",
    "    print 'tfidf vectoriser:', score_tvec\n",
    "    \n",
    "    \n",
    "    \n",
    "    scores_cvec.append(score_cvec)\n",
    "    scores_tvec.append(score_tvec)\n",
    "    print '_'*70\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>scores_cvec</th>\n",
       "      <th>scores_tvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.895433</td>\n",
       "      <td>0.856268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.895830</td>\n",
       "      <td>0.895413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StochasticGradientDescent</td>\n",
       "      <td>0.893775</td>\n",
       "      <td>0.907514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>0.402536</td>\n",
       "      <td>0.647989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.732085</td>\n",
       "      <td>0.749164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.837094</td>\n",
       "      <td>0.842094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  scores_cvec  scores_tvec\n",
       "0         LogisticRegression     0.895433     0.856268\n",
       "1               RandomForest     0.895830     0.895413\n",
       "2  StochasticGradientDescent     0.893775     0.907514\n",
       "3       SupportVectorMachine     0.402536     0.647989\n",
       "4                 KNeighbors     0.732085     0.749164\n",
       "5              MultinomialNB     0.837094     0.842094"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = ['LogisticRegression', 'RandomForest', 'StochasticGradientDescent', 'SupportVectorMachine', 'KNeighbors', 'MultinomialNB']\n",
    "mod_score = pd.DataFrame(zip(mod, scores_cvec, scores_tvec), columns = ['Model', 'scores_cvec', 'scores_tvec'])\n",
    "mod_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGVCAYAAAAR9e3TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBAWiKQQQghhgUgKIYQQFvhfwzi0MM5qxIYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111146390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pointplot(x='Model', y='scores_cvec', data =mod_score, label = 'cvec')\n",
    "sns.pointplot(x='Model', y='scores_tvec', color='r' ,data =mod_score, label = 'tvec')\n",
    "sns.pointplot(x='Model', y= [baseline, baseline, baseline, baseline, baseline, baseline], color='g' ,data =mod_score, label = 'baseline')\n",
    "\n",
    "\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.xlabel('Models')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy Scores of Different Models')\n",
    "# plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tuning models with highest scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LogisticRegression\t0.888761\n",
    "RandomForest\t0.897925\t0.886264\n",
    "StochasticGradientDescent\t0.895417\t0.911259"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen methods for \n",
    "\n",
    "Count Vectorizer - blue\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "\n",
    "Tfidf - Red\n",
    "- Random Forest\n",
    "- SGDClassifier\n",
    "\n",
    "RandomForestClassifier\t0.935008\t0.936253 very close scores so both will be searched\n",
    " \n",
    "With limited time I have chosen a localised method to choose my classifier\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Count Vectorizer and LogReg\n",
    "### to perform gridsearch for optimal parameters\n",
    "\n",
    "- Different parameters work best in different combinations and different models. \n",
    "- gridseach will help us find the best ones for in combination for logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2688 candidates, totalling 8064 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1387 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1837 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2387 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3037 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3787 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4637 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5587 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6637 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7787 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8064 out of 8064 | elapsed: 19.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (1, 4)), 'vect__max_df': (0.25, 0.5, 0.75, 1.0), 'clf__solver': ['liblinear'], 'clf__penalty': ['l1', 'l2'], 'clf__C': array([1.e-10, 1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03,\n",
       "       1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
       "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]), 'vect__max_features': (None, 5000, 10000, 50000)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "p_cvec_lr = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_cvec_lr = {'vect__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "          'vect__max_features': (None, 5000, 10000, 50000),\n",
    "          'vect__ngram_range': ((1, 1), (1, 2), (1,3), (1,4)), \n",
    "          'clf__penalty': ['l1','l2'],\n",
    "          'clf__solver':['liblinear'],\n",
    "          'clf__C': np.logspace(-10,10,21)\n",
    "         }\n",
    "\n",
    "grid_search = GridSearchCV(p_cvec_lr, param_cvec_lr, n_jobs=-1, verbose=1, cv=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.3\n",
      "Best score: 0.916\n",
      "\n",
      "\tclf__C: 10.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tclf__solver: 'liblinear'\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: 5000\n",
      "\tvect__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "print 'Baseline:', baseline\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print\n",
    "#### get the best parameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(param_cvec_lr.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(p_cvec_lr, param_cvec_lr, X_train, y_train):\n",
    "\n",
    "    grid_search = GridSearchCV(p_cvec_lr, param_cvec_lr, n_jobs=-1, verbose=1, cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print 'Baseline:', baseline\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print\n",
    "    #### get the best parameters\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(param_cvec_lr.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grid_search:\n",
    "    def __init__(self, pipeline, parameters):\n",
    "        \n",
    "        self.pipeline = pipeline\n",
    "        self.parameters = parameters \n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        GridSearchCV(self.pipeline, self.parameters, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        return self.fit(X_train,y_train)\n",
    "  \n",
    "    def best_score(self):\n",
    "        return gs.best_score_\n",
    "        \n",
    "        \n",
    "    def best_params(self):\n",
    "        best_parameters = gs.best_estimator_.get_params()\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            return best_parameters  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-07b303d103d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_cvec_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_cvec_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-acba489d583e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m<ipython-input-107-acba489d583e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "p_cvec_lr = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_cvec_lr = {'vect__max_df': (0.25, 0.5),\n",
    "#           'vect__max_features': (None, 5000, 10000, 50000),\n",
    "#           'vect__ngram_range': ((1, 1), (1, 2), (1,3), (1,4)), \n",
    "          'clf__penalty': ['l1','l2'],\n",
    "          'clf__solver':['liblinear'],\n",
    "#           'clf__C': np.logspace(-10,10,21)\n",
    "         }\n",
    "\n",
    "grid = grid_search(p_cvec_lr, param_cvec_lr)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "#         from sklearn.model_selection import GridSearchCV\n",
    "#         gs = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=3)\n",
    "#         gs.fit(X_train, y_train)\n",
    "#         print gs.best_score_ \n",
    "\n",
    "        \n",
    "#     grid_search = GridSearchCV(p_cvec_lr, param_cvec_lr, n_jobs=-1, verbose=1, cv=3)\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     print 'Baseline:', baseline\n",
    "#     print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "#     print\n",
    "#     gs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pipeline Tune Hyperparameters\n",
    "- CountVectorizer \n",
    "- TfidfVectorizer\n",
    "- RandomForestClassifier\n",
    "- SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest \n",
    "- CountVectorizer \n",
    "- TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Count Vec && Random Forest\n",
    "p_cvec_rf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "param_cvec_rf = {'vect__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "                 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                 'vect__ngram_range': ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "                 'clf__max_depth':[None,1,2,3,4,5,6],\n",
    "#                  'clf__max_features':[1,2,3,4], ???\n",
    "                 'clf__max_leaf_nodes':[5,6,7,8,9,10], \n",
    "                 'clf__min_samples_leaf':[1,2,3,4],\n",
    "#                  'clf__min_samples_split':[1,2,3,4]???\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "#### Tfidf Vec && Random Forest\n",
    "p_tvec_rf = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "param_tvec_rf = {'vect__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "                 'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "                 'clf__max_depth':[None,1,2,3,4,5,6],\n",
    "#                  'clf__max_features':[1,2,3,4], \n",
    "                 'clf__max_leaf_nodes':[5,6,7,8,9,10], \n",
    "                 'clf__min_samples_leaf':[1,2,3,4],\n",
    "#                  'clf__min_samples_split':[1,2,3,4]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10752 candidates, totalling 32256 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14442 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=-1)]: Done 18042 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=-1)]: Done 19992 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 22042 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 24192 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 26442 tasks      | elapsed: 40.4min\n",
      "[Parallel(n_jobs=-1)]: Done 28792 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=-1)]: Done 31242 tasks      | elapsed: 47.9min\n",
      "[Parallel(n_jobs=-1)]: Done 32256 out of 32256 | elapsed: 49.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.3\n",
      "Best score: 0.570\n",
      "\n",
      "\tclf__max_depth: None\n",
      "\tclf__max_leaf_nodes: 10\n",
      "\tclf__min_samples_leaf: 2\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 50000\n",
      "\tvect__ngram_range: (1, 1)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print grid_search(p_cvec_rf, param_cvec_rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2016 candidates, totalling 6048 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6048 out of 6048 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.3\n",
      "Best score: 0.578\n",
      "\n",
      "\tclf__max_depth: None\n",
      "\tclf__max_leaf_nodes: 10\n",
      "\tclf__min_samples_leaf: 4\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__ngram_range: (1, 2)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print grid_search(p_tvec_rf, param_tvec_rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDC \n",
    "- CountVectorizer\n",
    "- TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Count Vec && SGDC\n",
    "p_cvec_sg = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SGDClassifier())\n",
    "    ])\n",
    "\n",
    "param_cvec_sg = {'vect__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "                 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                 'vect__ngram_range': ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "                 'clf__loss': ['log'],\n",
    "                 'clf__penalty': ['l1','l2'],\n",
    "                 'clf__alpha': np.logspace(-5,1,15)\n",
    "                }\n",
    "\n",
    "                    \n",
    "#### Tfidf Vec && SGDC\n",
    "p_tvec_sg = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', SGDClassifier())\n",
    "    ])\n",
    "\n",
    "\n",
    "param_tvec_sg = {'vect__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "                 'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "                 'clf__loss': ['log'],\n",
    "                 'clf__penalty': ['l1','l2'],\n",
    "                 'clf__alpha': np.logspace(-5,1,15)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "('pipeline:', ['vect', 'clf'])\n",
      "Fitting 3 folds for each of 1920 candidates, totalling 5760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5760 out of 5760 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 476.514s\n",
      "\n",
      "Baseline: 0.3\n",
      "Best score: 0.918\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'clf__C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ff66d54cdf2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mgridsearch_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_cvec_sg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_cvec_sg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-6f7b4f8b9245>\u001b[0m in \u001b[0;36mgridsearch_def\u001b[0;34m(pipeline, parameters, X_train, y_train)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_cvec_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t%s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clf__C'"
     ]
    }
   ],
   "source": [
    "print grid_search(p_cvec_sg, param_cvec_sg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.3\n",
      "Best score: 0.920\n",
      "\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__loss: 'log'\n",
      "\tclf__penalty: 'l1'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__ngram_range: (1, 3)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print grid_search(p_tvec_sg, param_tvec_sg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With limited time I have chosen a localised method to choose my classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Notes for model! \n",
    "An example of a model statement might look like this:\n",
    "\"Completed a logistic regression using Statsmodels. Calculated the probability of a customer placing another order with the company.\"\n",
    "Here, we are using a logistic model because we are trying to determine the probability that a customer might place a return order, which is - at its heart - a classification problem.\n",
    "\n",
    "Share your technical findings with your fellow data scientists. Explain your goals, describe modeling choices, evaluate model performance, and discuss results. Data science reporting is technical, but don’t forget that you should tell a compelling story about your data.\n",
    "\n",
    "- **Requirements**: Summarize your goals and metrics for success, variables of interest, and removal of any outliers or data imputation. Your process description should be concise and relevant to your goals. Summarize statistical analysis, including model selection,  implementation, evaluation, and inference. Be convincing – justify all important decisions! Clearly label plots and visualizations. Include an Executive Summary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  null values \n",
    "I checked for null values when loading the cleaned training data and found 1 row. It was identified that the text of the review was one numeric value before the cleaning process. This must have been an empty value which was then saved into the csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision Trees \n",
    "max_depth\tHow many nodes deep can the decision tree go?\n",
    "max_features\tIs there a cut off to the number of features to use?\n",
    "max_leaf_nodes\tHow many leaves can be generated per node?\n",
    "min_samples_leaf\tHow many samples need to be included at a leaf, at a minimum?\n",
    "min_samples_split\tHow many samples need to be included at a node, at a minimum?\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
